{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7oOwS5XZh19"
   },
   "source": [
    "# SISU Digital Humanities: Textual and Language Analysis on Social Media<br />\n",
    "### Session 5: Classification and Sentiment Analysis\n",
    "Created by Tom van Nuenen (tom.van_nuenen@kcl.ac.uk) <br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A5tRlY3nZh1-"
   },
   "source": [
    "#  Classification\n",
    "\n",
    "This notebook introduces some common methods for **classification**.\n",
    "\n",
    "First, we’ll be using a Naive Bayes Classifier to differentiate between different \"classes\" of data. We will look at some tools for sentiment analysis. Finally, we'll combine these two methods, so we can see if we can predict positive and negative posts or comments in a Reddit dataset.\n",
    "\n",
    "After working through today's notebook, you will:\n",
    "\n",
    "1. understand how to use a **Naive Bayes classifier** using social data;\n",
    "2. understand how to use a pre-trained sentiment analysis tool using **NLTK VADER**;\n",
    "3. understand how to train a Naive Bayes classifier for a **supervised class of sentiments** (i.e., creating and training your own sentiment analysis tool).\n",
    "\n",
    "Let's get started.\n",
    "\n",
    "\n",
    "## Introduction to Naive Bayes classifiers\n",
    "\n",
    "A Naive Bayes classifier is a machine learning algorithm that uses **Bayes’ Theorem** to predict the class that a sample belongs to, given a number of features that describe that sample. It is based on the concept of conditional probability: “What is the probability of X, given Y?”. Which in our case is: \"What is the probability of a post belonging to a category, given its word frequencies?\" The math behind Bayes' Theorem is simple but intuitive. For more info, check out http://www.dealingdata.net/2016/07/24/PoGo-Series-NaiveBayesClassifier/.\n",
    "\n",
    "Naive Bayes classifiers are often considered the baseline for classification tasks. They have worked quite well in many real-world situations, famously document classification and spam filtering. Mathematically speaking, they are very straightforward, you can use them when you have limited resources in terms of CPU and memory. Further, when the training time is a crucial factor, a Naive Bayes classifier is convenient, as it can be trained very quickly. \n",
    "\n",
    "One peculiar aspect of Naive Bayes classifiers is that they assume that the features you use are *conditionally independent*: knowledge of the outcome of one feature does not grant us knowledge of the outcome of any other feature. When dealing with text, this means that we’re not looking at entire sentences, but rather at individual words. So for our purposes, “this was a fun party” is the same as “this party was fun” and “party fun was this”. This is a pretty naive assumption (separate features are often correlated) — hence the name Naive Bayes Classifier. Yet, it turns out the algorithm often performs just as well than much more complex machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6273,
     "status": "ok",
     "timestamp": 1596638069748,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "92-uzgw6Zh1_",
    "outputId": "58ce6543-f0c8-4034-f260-4aad93d7daed",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction import text\n",
    "stop = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "# NLTK \n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.classify import apply_features\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import accuracy\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.metrics import precision as prec\n",
    "from nltk.metrics import recall as rec\n",
    "from nltk.metrics import f_measure as fmeas\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt') \n",
    "\n",
    "# pickle for saving\n",
    "import pickle\n",
    "\n",
    "# SpaCy \n",
    "import spacy\n",
    "!spacy download en_core_web_sm\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load(disable=['parser', 'ner'])\n",
    "\n",
    "# VADER - installing using magic command `!pip install vaderSentiment` (command line script)\n",
    "!pip install vaderSentiment\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Gensim's preprocessor\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# General data science\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import collections\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6kLcYKobZh2G"
   },
   "source": [
    "## Test using 20 Newsgroups\n",
    "\n",
    "The 20 newsgroups dataset consists of around 18000 newsgroups posts on 20 topics. It's helpfully split in two subsets: one for training (i.e. development), and one for testing (i.e. performance evaluation). \n",
    "\n",
    "We will use a Naive Bayes classifier to **predict the topics of the posts in our test set**, based on the **word frequencies** in the posts in our training set. \n",
    "\n",
    "First, let's get the data. The `.target_names` method yields the topics that the newsgroups have been classified in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SOt10CYJZh2G"
   },
   "outputs": [],
   "source": [
    "data = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1435,
     "status": "ok",
     "timestamp": 1596637291335,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "ugSYmOUG_5OL",
    "outputId": "cdd986aa-ff8a-47d7-a518-f217f5e497cc"
   },
   "outputs": [],
   "source": [
    "data.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cw_yEuIwZh2L"
   },
   "source": [
    "Let's just get four of those to do our test with. We create a **training set** and a **test set**. The training set is, as the name implies, to train our classifier on. The test set we use to evaluate the performance of that classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1783,
     "status": "ok",
     "timestamp": 1596637400111,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "P3uzq1PbZh2M"
   },
   "outputs": [],
   "source": [
    "categories = ['talk.religion.misc', 'soc.religion.christian',\n",
    "              'sci.space', 'comp.graphics']\n",
    "train = fetch_20newsgroups(subset='train', categories=categories)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "53SVW8StAWuH"
   },
   "source": [
    "What does the data look like?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1149,
     "status": "ok",
     "timestamp": 1596637406700,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "8ICNv8mJZh2P",
    "outputId": "5e4ecdae-05e1-4571-af95-e88490e57bd3"
   },
   "outputs": [],
   "source": [
    "test.data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vXyqHlD9Zh2S"
   },
   "source": [
    "To convert the content of each string into a vector of numbers, we will use Scikit-learn's `TfidfVectorizer()` method again.\n",
    "\n",
    "We're using sklearn's `MultinomialNB` as our classifier. **Multinomial Naive Bayes** is a specialized version of Naive Bayes that is specifically designed for text documents. Whereas *Simple Naive Bayes* would model a document as the presence and absence of particular words, *Multinomial Naive Bayes* explicitly models all the word counts and adjusts the underlying calculations. For more on the difference between these classifiers, see:\n",
    "http://blog.datumbox.com/machine-learning-tutorial-the-naive-bayes-text-classifier/ \n",
    "\n",
    "Scikit-klearn allows us to create a **pipeline** using `make_pipeline()`, which attaches this vectorizer to a multinomial naive Bayes classifier (meaning we don't have to instantiate these methods separately)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1515,
     "status": "ok",
     "timestamp": 1596637550998,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "UoJH0bNhZh2T"
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kd_-mpZZh2W"
   },
   "source": [
    "### Fitting the data\n",
    "\n",
    "With this pipeline, we can apply the model to the training data, and then predict labels for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1536,
     "status": "ok",
     "timestamp": 1596637553862,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "kS5bcRveZh2X"
   },
   "outputs": [],
   "source": [
    "model.fit(train.data, train.target)\n",
    "labels = model.predict(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1160,
     "status": "ok",
     "timestamp": 1596637553863,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "d2kdy0wEZh2c",
    "outputId": "80a6ccab-f120-46a5-ad4f-2e66f6a6a368"
   },
   "outputs": [],
   "source": [
    "labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4WazqxP9Zh2f"
   },
   "source": [
    "Now that we have predicted the labels for the test data, we can evaluate them to learn about the performance of the estimator. For example, here is the confusion matrix between the true and predicted labels for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1596637568531,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "088ylqrUZh2g",
    "outputId": "3fd9662f-0f18-42ca-92a2-85d5abb8f8a9"
   },
   "outputs": [],
   "source": [
    "mat = confusion_matrix(test.target, labels)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QdkPbe78Zh2j"
   },
   "source": [
    "Evidently, even this very simple classifier based on tf-idf scores can successfully separate posts about space from posts about computers. It gets confused, however, between talk about religion and talk about Christianity – an expected area of confusion.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAZIndhPZh2k"
   },
   "source": [
    "### Prediction\n",
    "With this classifier, we can now determine the category for any string, using the `predict()` method of this pipeline. Let's write a utility function that will return the prediction for a single string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 868,
     "status": "ok",
     "timestamp": 1596637718482,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "GJWF5EoLZh2k"
   },
   "outputs": [],
   "source": [
    "def predict_category(s, train=train, model=model):\n",
    "    pred = model.predict([s])\n",
    "    return train.target_names[pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1057,
     "status": "ok",
     "timestamp": 1596637722016,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "YZzDrageZh2n",
    "outputId": "64ed6721-0956-4ac7-fb8e-d186483b4ae0"
   },
   "outputs": [],
   "source": [
    "predict_category('Scientists discover new moon around Saturn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VV-gmENZZh2r"
   },
   "source": [
    "It works!\n",
    "\n",
    "**Remember:** this is nothing more than a simple probability model for the (weighted) frequency of each word in the string! Nevertheless, the result is striking. Even a very naive algorithm, when used carefully and trained on a large set of high-dimensional data, can be surprisingly effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfeqs_V-Zh2r"
   },
   "source": [
    "## Classification on social media\n",
    "\n",
    "We will now use the same technique on an online community. We'll be using a community in which members can vote whether an original poster [OP], in some social interaction, behaved \"assholeish\". We want to explore whether we can predict this classification, based on the words that members use.\n",
    "\n",
    "*Note: This is an example of a hypothesis that will fail. I include it because failure is an important part of the job of the data scientist. You have to get used to trying out things that will fail.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wDeidiecZOop"
   },
   "source": [
    "### Preprocessing\n",
    "\n",
    "We'll start by cleaning up our data a bit. Let's load it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4902,
     "status": "ok",
     "timestamp": 1596638870615,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "1cY6-yUcZOoq",
    "outputId": "3e4c873e-a118-44a6-eb52-612dfe7689f4"
   },
   "outputs": [],
   "source": [
    "# load into df\n",
    "df = pd.read_csv(\"data/amita-submissions.csv\", lineterminator='\\n', encoding=\"utf8\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4599,
     "status": "ok",
     "timestamp": 1596638870616,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "BobIKSa8Zh2t",
    "outputId": "b11d58ba-b1a1-4e8c-a998-275528a1a652",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# clean up empty entries\n",
    "df = df.drop(['augmented_at', 'augmented_count', 'distinguish'], axis=1)\n",
    "df = df[~df['selftext'].isin(['[removed]', '[deleted]' ])].dropna(subset=['selftext'])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RIgcztQ4Zh2w"
   },
   "source": [
    "**Note:** if working with this entire dataset is still taking too long, consider using a slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1596637959063,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "VamFANgBZh2x",
    "outputId": "97725ccc-0aa1-4d9e-d816-eecec11a896b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_tfxb_-Zh21"
   },
   "source": [
    "We can clean up some of the text in our DataFrame using a function which we `apply()` to the selftext column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2572,
     "status": "ok",
     "timestamp": 1596638951010,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "_YEAgyjoZh21"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Normalize tabs and remove newlines\n",
    "    no_tabs = text.replace('\\t', ' ').replace('\\n', '');\n",
    "    # Remove all characters except A-Z and a dot.\n",
    "    alphas_only = re.sub(\"[^a-zA-Z\\.]\", \" \", no_tabs);\n",
    "    # Normalize spaces to 1\n",
    "    multi_spaces = re.sub(\" +\", \" \", alphas_only);\n",
    "    # Strip trailing and leading spaces\n",
    "    no_spaces = multi_spaces.strip();\n",
    "    return no_spaces\n",
    "\n",
    "df[\"selftext_clean\"] = df[\"selftext\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5KfKs5QZh25"
   },
   "source": [
    "### A classifier for assholes?\n",
    "\n",
    "Now that we've seen how classification works, let's write a classifier for this subreddit. A typical use of this would be, for instance, to classify which particular subreddit a post belongs to. Or to classify posts that should be categorized as \"NSFW\".\n",
    "\n",
    "But you can also use classification to test out certain hypotheses: for instance, can we predict whether a post will be classified as \"ITA\" (*Is The Asshole*), given its textual features?\n",
    "\n",
    "Luckily, the members of r/amitheasshole have done some work for us by labeling the posts. We can use these labels to train our classifier. Let's have a look at the `flair_css_class` column in our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1105,
     "status": "ok",
     "timestamp": 1596638873360,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "ZUvOYdwvZh26",
    "outputId": "28423424-6ecf-4b43-ff2d-e41fdd9f2ec0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['flair_css_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1dGxPvHZh2-"
   },
   "source": [
    "Looks like the `flair_css_class` column contains lots of tags for asshole and non-asshole posts. Let's use this column for now. We'll remove anything that's *not* classified as `not` or `ass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1229,
     "status": "ok",
     "timestamp": 1596638895112,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "arX-cAJaZh2_",
    "outputId": "883a7add-a6b2-4670-eff0-98918523bed5"
   },
   "outputs": [],
   "source": [
    "df = df[~df['flair_css_class'].isin(['shitpost', '1' ])].dropna(subset=['flair_css_class'])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NobKEzQZh3D"
   },
   "source": [
    "The next issue is that we have an unbalanced classification: \"Not the Asshole\" (`not`) posts occur over double as many times as \"Asshole\" (`ass`). We can choose to either **upsample** our \"Asshole\" category (by adding doubles) or **downsampling** our \"Not the A-hole\" category by removing entries. You ideally have to try both, as what works best differs from case to case, but let's downsample for now. \n",
    "\n",
    "First, we want our DataFrame sorted. Then, we create a boolean mask for the negative values, use `np.where` to get the indices of these rows, `drop` these indices, then drop one half of those indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1063,
     "status": "ok",
     "timestamp": 1596640358827,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "DjH-L3b6Zh3D"
   },
   "outputs": [],
   "source": [
    "# Sorting the values\n",
    "df.sort_values('flair_css_class', inplace=True)\n",
    "\n",
    "# creating a mask for the condition\n",
    "mask = (df.flair_css_class == \"not\")\n",
    "\n",
    "# find out which indexes this condition refers to using np.where()\n",
    "idx, = np.where(mask)\n",
    "\n",
    "# divide by 2 and drop the indices\n",
    "df.drop(df.index[idx[:len(idx)//2]], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NI78mD1GLhwR"
   },
   "source": [
    "Let's see how many entries for our classes we have now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 929,
     "status": "ok",
     "timestamp": 1596640361955,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "Rob-rhLRLeP-",
    "outputId": "c6f46c83-d069-433e-c866-df7d065c3a80"
   },
   "outputs": [],
   "source": [
    "df['flair_css_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6TlscDpmZh3H"
   },
   "source": [
    "Looks more balanced now!\n",
    "\n",
    "Next, let's work on our input features. We'll start by lemmatizing and POS-filtering our texts. We'll output strings for each post which we can then load into our vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1407,
     "status": "ok",
     "timestamp": 1596641144870,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "1EV0FTpmZh3H"
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english') + ['’', '“', '”', 'nbsp', 'http', 'edit'])\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'VERB', 'ADJ', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    out = []\n",
    "    for text in texts:\n",
    "        doc = nlp(text) \n",
    "        stop_out = [token for token in doc if token not in stop]\n",
    "        out.append(' '.join([token.lemma_ for token in stop_out if token.pos_ in allowed_postags]))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 86226,
     "status": "ok",
     "timestamp": 1596641232166,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "csdh6GCDZh3K"
   },
   "outputs": [],
   "source": [
    "lemmas = lemmatization(df.selftext_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 85957,
     "status": "ok",
     "timestamp": 1596641232168,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "c487Jhn-JXer",
    "outputId": "f4c4a5f6-c370-446f-928e-74afc56586f0"
   },
   "outputs": [],
   "source": [
    "lemmas[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5OZ4XJ8pZh3Q"
   },
   "source": [
    "Lemmatizing takes a long time, so we don't want to do it twice. We'll save the lemmatized list in a pickle, in case we need it later. Note that you can download files from your Colab workspace by clicking the folder icon to the left and clicking \"download\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 81746,
     "status": "ok",
     "timestamp": 1596638558046,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "xkNfRwa6Zh3Q"
   },
   "outputs": [],
   "source": [
    "# pickling\n",
    "with open(\"lemmas.lem\", \"wb\") as cp: \n",
    "    pickle.dump(lemmas, cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 975,
     "status": "ok",
     "timestamp": 1596638223583,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "UhX9w8AuZh3S"
   },
   "outputs": [],
   "source": [
    "# unpickling\n",
    "with open(\"lemmas.lem\", \"rb\") as cp: \n",
    "    lemmas = pickle.load(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J-O-DEjUZh3V"
   },
   "source": [
    "### Commence training\n",
    "\n",
    "Now for the classfier! We'll first create our training and test set, using the lemmas as `X` and `flair_css_class` as `y`. So we're predicting `y` given `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1343,
     "status": "ok",
     "timestamp": 1596641271880,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "3JdK3MbCZh3W"
   },
   "outputs": [],
   "source": [
    "X = lemmas\n",
    "y = df['flair_css_class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w8zRQxjnZh3Z"
   },
   "source": [
    "Next, we split our data into training and test sets again. We can easily do this using scikit-learn's `train_test_split()` method. The method takes a parameter denoting the size of the test set (20% of the total set, in this case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1596641271881,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "SOG6EFYxZh3a"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9R_1wQkZh3e"
   },
   "source": [
    "Why are we splitting into training and testing sets before vectorizing?\n",
    "\n",
    "If we vectorize *before* we train/test split, our doc-term matrix would contain every single feature (word) in the test and training sets. What we want is to simulate the real world, where our classifier needs to encounters words it has not seen before. This allows us to evaluate it better.\n",
    "\n",
    "So here's what we're doing: \n",
    "\n",
    "- We create a `TfidfVectorizer` instance\n",
    "- `vect.fit.transform(X_train)` learns the t-fidf vocabulary of the training data, and uses the fitted vocabulary to build a document-term matrix from the training data;\n",
    "- `vect.transform(X_test)` uses the fitted vocabulary to build a document-term matrix from the testing data (and ignores tokens it hasn't seen before)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1486,
     "status": "ok",
     "timestamp": 1596641274739,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "PkpEXpiMZh3f",
    "outputId": "91803c5a-8778-49f1-af05-e10732dc88e4"
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_df=1.0, max_features=None, min_df=1) # we can add ngram_range=(1, 2) to include N-grams\n",
    "\n",
    "# learn training data vocabulary, then use it to create a document-term matrix\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "# transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QxGDyW1hZh3i"
   },
   "source": [
    "Time to create the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1475,
     "status": "ok",
     "timestamp": 1596641275226,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "JWtVY_FRZh3i",
    "outputId": "6dad72a6-55a4-4cfe-da51-214bd712e61c"
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB()\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "txTEsCUDZh3l"
   },
   "source": [
    "That was quick! Let's see what it yields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1596640459207,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "SSQmwNFsZh3l",
    "outputId": "40c5fa76-dd60-4a3b-e9a4-9081e42fa33f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make class predictions for X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "# Calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 939,
     "status": "ok",
     "timestamp": 1596641285684,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "WPxFORXUZh3o",
    "outputId": "ac91ddbb-ee76-43e6-dd12-ec2f65067ae1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "categories = ['ass', 'not']\n",
    "mat = confusion_matrix(y_test, y_pred_class)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZp_FeIBZh3r"
   },
   "source": [
    "Well, that doesn't work very well!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0jMbvaKPZh3s"
   },
   "source": [
    "### OPTIONAL: Classification using logistic regression\n",
    "\n",
    "Our predictions are not particularly accurate. This is no surprise, as it would be quite a feat to predict this class based on word usage alone! If you'd want to pursue this hypothesis further, you could try to take more features for X into account. \n",
    "\n",
    "Just for fun, let's try comparing this result to **logistic regression**, which is also often used for classification problems. Logistic regression tries to find the optimal decision boundary that best separates classes.\n",
    "\n",
    "The difference between Naive Bayes and Logistic regression is that the first is a generative model, and the second a discriminative model. What does this mean?\n",
    "- **Generative model**: Naive Bayes models the joint distribution of the feature X and target y, and then *predicts* the posterior probability given as P(y|X)\n",
    "- **Discriminative model**: Logistic regression *directly models* the posterior probability of P(y|X) by learning the input to output mapping and minimizing the error.\n",
    "\n",
    "Unlike Naive Bayes, logistic regression typically works reasonably well even when some of the features (in our case, words) are correlated. This is why it can be a good idea to try both when dealing with texts (because certain words *do* tend to appear in each other's vicinity!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1269,
     "status": "ok",
     "timestamp": 1596641295999,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "LZv1bpRaZh3s"
   },
   "outputs": [],
   "source": [
    "# instantiate a logistic regression model\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1519,
     "status": "ok",
     "timestamp": 1596641296529,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "se7nezO_Zh3w",
    "outputId": "04e052c8-ca50-4f17-9250-dd6da2a19ea8"
   },
   "outputs": [],
   "source": [
    "# train the model using X_train_dtm\n",
    "%time logreg.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1295,
     "status": "ok",
     "timestamp": 1596641296531,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "DrD54i3PZh3y"
   },
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_class = logreg.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1596641296531,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "3HA25D0fZh31",
    "outputId": "57eccf11-4a0e-435a-fb77-3bdce62b5e85"
   },
   "outputs": [],
   "source": [
    "# calculate predicted probabilities for X_test_dtm\n",
    "y_pred_prob = logreg.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1596641296532,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "jKqAj5XpZh33",
    "outputId": "f5636582-93dc-4a25-c864-0adb6bf4af57",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate accuracy\n",
    "metrics.accuracy_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G-xenYmXZh36"
   },
   "source": [
    "Still no good – but you get the idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_tAYGMaxZh37"
   },
   "source": [
    "### Improving the model\n",
    "\n",
    "If you'd want to improve upon this model, you could try to extract other features from the text (for instance, based on the presence of certain words, sentence length, etc.). You could also start looking into other features from the metadata (e.g. the score it received) to improve the prediction – though this is beyond the scope of this notebook.\n",
    "\n",
    "What you need to know is that this process is called **feature engineering**: taking whatever information you have about your problem and turning it into numbers that you can use to build your feature matrix.\n",
    "\n",
    "Plugging other features into a classifier could potentially make it more accurate. For now, we can say that we cannot really tell the label based only on the words that people use in their posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86yH3K8gZh37"
   },
   "source": [
    "### Finding the most distinctive terms\n",
    "\n",
    "Before we move on, let's explore why we would want an accurate model in the first place! For one, this would allow us to calculate the approximate \"assholishness\" of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1596641465612,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "W3e03LYnZh38",
    "outputId": "8a86ecb3-17bb-4100-b850-83b4ec70f20f"
   },
   "outputs": [],
   "source": [
    "# store the vocabulary of X_train\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1596641489132,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "BP6sp8YbZh4B",
    "outputId": "6fd3b28c-c45d-478f-cbdd-f98e52ced045"
   },
   "outputs": [],
   "source": [
    "# examine some tokens\n",
    "print(X_train_tokens[100:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k0oP92h-QAy9"
   },
   "source": [
    "Naive Bayes counts the number of times each token appears in each class. We can access the array of that count by running the `.feature_count_` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1218,
     "status": "ok",
     "timestamp": 1596641498284,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "BJrm5uoPZh4D",
    "outputId": "387fb9b9-f9e5-4247-f314-9fae6e89b0bb"
   },
   "outputs": [],
   "source": [
    "# note that the trailing underscore often acts to avoid naming errors\n",
    "nb.feature_count_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oXTq54cCQlQO"
   },
   "source": [
    "What are we seeing here? The rows represent our classes (asshole / not an asshole), the columns represent our tokens (our total vocabulary).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 932,
     "status": "ok",
     "timestamp": 1596641498285,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "xY5OhscsZh4G",
    "outputId": "c774c4d7-df95-4cb4-b3a6-66f3e866005a"
   },
   "outputs": [],
   "source": [
    "# rows represent classes, columns represent tokens\n",
    "nb.feature_count_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1596641706300,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "foPzSHKOZh4K",
    "outputId": "23851411-7a66-42a0-8da7-9ba09871ba5e"
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across all ASS posts\n",
    "ass_token_count = nb.feature_count_[0, :]\n",
    "ass_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1596641856416,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "hx9YFtPNZh4M",
    "outputId": "365de26e-22ba-46d6-a875-29741bb2c8cf"
   },
   "outputs": [],
   "source": [
    "# number of times each token appears across all NOT posts\n",
    "not_token_count = nb.feature_count_[1, :]\n",
    "not_token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fisNTo6RROc1"
   },
   "source": [
    "We can now create a DataFrame of tokens with their separate ASS and NOT counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1596641887690,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "_HhyTR6rZh4Q",
    "outputId": "81a2fca0-edbd-4efc-f4cd-cac18c0c7fab",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokens = pd.DataFrame({'token':X_train_tokens, 'ass':ass_token_count, 'not':not_token_count}).set_index('token')\n",
    "tokens[110:120] # just a random slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kwi7-mcsRl6i"
   },
   "source": [
    "Using `.class_count_`, we can count the number of observations in each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 923,
     "status": "ok",
     "timestamp": 1596641950412,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "5yTWTl_qZh4V",
    "outputId": "1a64632e-e844-456d-e571-f87e3842f6a7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Naive Bayes counts the number of observations in each class\n",
    "nb.class_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 900,
     "status": "ok",
     "timestamp": 1596641986395,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "ClI4U7QVZh4Y",
    "outputId": "71aaf12a-0d9a-4d92-d2af-9e4428bc4765",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# add 1 to 'ass' and 'not' counts to avoid dividing by 0\n",
    "tokens['ass'] = tokens['ass'] + 1\n",
    "tokens['not'] = tokens['not'] + 1\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 854,
     "status": "ok",
     "timestamp": 1596642002508,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "VU5nSXh3Zh4b",
    "outputId": "be013938-d35e-495b-dead-f6dc4b3b421a"
   },
   "outputs": [],
   "source": [
    "# convert the 'ass' and 'not' counts into frequencies\n",
    "tokens['ass'] = tokens['ass'] / nb.class_count_[0]\n",
    "tokens['not'] = tokens['not'] / nb.class_count_[1]\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 991,
     "status": "ok",
     "timestamp": 1596642010524,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "GIVy9xmUZh4e",
    "outputId": "684d423a-d052-4896-825d-9f9245922f0d"
   },
   "outputs": [],
   "source": [
    "# calculate the ratio of ass-to-not for each token\n",
    "tokens['ass_ratio'] = tokens['ass'] / tokens['not']\n",
    "tokens.sample(5, random_state=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nH8mWcAnR9sf"
   },
   "source": [
    "Finally, we can examine the DataFrame sorted by ass_ratio. These are the words, according to our classifier, that are the most typical of \"assholeish\" posts. A well-working classifier would yield interesting info here on how telling each word is for being considered an asshole by the community. But then again, creating such a classifier is not a trivial matter.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 390
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1596642020322,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "YO7FYCGHZh4h",
    "outputId": "7afb0063-6066-4a80-a671-a66dfe9faea1"
   },
   "outputs": [],
   "source": [
    "# note: use sort() instead of sort_values() for pandas 0.16.2 and earlier\n",
    "tokens.sort_values('ass_ratio', ascending=False)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1118,
     "status": "ok",
     "timestamp": 1596642151744,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "dFAf18XCZh4j",
    "outputId": "de807ab5-c1a6-45a7-f53a-16f8ac4cab4e"
   },
   "outputs": [],
   "source": [
    "# look up the not_ratio for a given token\n",
    "tokens.loc['me', 'ass_ratio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SiQuWUN9Zh4l"
   },
   "source": [
    "Looks like the word 'me' occurs 3 as often for people who are classified as assholes (according to our very imprecise classifier at least). With a precise classifier, this would be a very interesting result!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wH_tIIPyZh4m"
   },
   "source": [
    "### Training for more classes\n",
    "\n",
    "We've trained for 2 classes now (asshole and non-asshole), but the posts in this subreddit (as well as many others) actually have more labels, called **flair**. We can find them here under the `flair_text` category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1346,
     "status": "ok",
     "timestamp": 1596642243643,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "zlfcXlTSZh4m",
    "outputId": "370c4b96-e499-4a4b-9fb2-3e91f49d5472",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.flair_text.unique()[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M2Qt_PAJZh4p"
   },
   "source": [
    "Quite a lot of categories, turns out. Let's see what the most-frequent categories are, as well as their counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1273,
     "status": "ok",
     "timestamp": 1596642247068,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "Bx1jHEb1Zh4p",
    "outputId": "0ea1fdbf-3648-4f58-828d-e8b3ebf1330e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['flair_text'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pD3Dlhs6Zh4s"
   },
   "source": [
    "There are a bunch of categories which we could concatenate in order to work with more data. This might make our classifier more accurate! For now, let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Osp8M8qTZh4t"
   },
   "source": [
    "# Automated sentiment analysis using NLTK VADER\n",
    "\n",
    "The second half of this notebook is about sentiment analysis (sometimes known as \"opinion mining\"). The most common use of sentiment analysis is to classify a text into a class (called \"sentiment classification\"). We'll get to that further on. First, let's see how sentiment analysis itself works.\n",
    "\n",
    "The simplest option is to use pre-built libraries for sentiment analysis. TextBlob and NLTK VADER are two examples of such libraties. VADER (Valence Aware Dictionary and sEntiment Reasoner) is specifically built for social media texts, and takes multiple text features into account, such as:\n",
    "\n",
    "- **Punctuation** (e.g. an exclamation mark \"!\" increases the magnitude of intensity)\n",
    "- **Capitalization** (e.g. \"The food here is GREAT\" is more intense than \"The food here is great\")\n",
    "- **Degree modifiers** (e.g. \"The service here is extremely good\" is more intense than \"The service here is good\")\n",
    "- **Conjunctions** signal a shift in sentiment polarity, with the sentiment of the text following the conjunction being dominant (e.g. “The food here is great, but the service is horrible”)\n",
    "- **Preceding Tri-grams** of a sentiment-laden lexical feature catch 90% of cases where negation flips the polarity of the text (e.g. \"The food here isn’t really all that great”)\n",
    "- **Emoji, emoticons & slang** are parsed very well by VADER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1155,
     "status": "ok",
     "timestamp": 1596642331363,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "J1tFJ5caZh4t"
   },
   "outputs": [],
   "source": [
    "# instantiate Class\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1021,
     "status": "ok",
     "timestamp": 1596648573879,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "3CQ9bOWtZh4x",
    "outputId": "ccff7f21-6625-4319-d927-946e1109924c"
   },
   "outputs": [],
   "source": [
    "# a small test\n",
    "analyser.polarity_scores(\"\"\"This is really dumb. I don't want to use this stupid \n",
    "                          program. But I slept really well.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFW3jV0qZh41"
   },
   "source": [
    "VADER spits out several metrics we can use. The **Positive**, **Negative** and **Neutral** scores represent the proportion of text that falls in these categories. This means our sentence was rated as 35% Positive, 50% Neutral and 15% Negative. All these add up to 1.\n",
    "\n",
    "The **Compound** score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1 (most extreme negative) and +1 (most extreme positive). The compound score turns out to be 0.61: a pretty positive sentiment overall. Let's use that score for now (but be aware that you can use these `neg`, `neu` and `pos` scores to your advantage to train a more precise classifier!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ws2-J4lsZh49"
   },
   "source": [
    "Now let's write a function that takes a text in, and spits out one of 3 tags based on the compound score, as well as that compound score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1019,
     "status": "ok",
     "timestamp": 1596642425430,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "ircdPv5AZh4-"
   },
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(text):\n",
    "    sentiment_dict = analyser.polarity_scores(text)\n",
    "    # decide sentiment as positive, negative and neutral \n",
    "    if sentiment_dict['compound'] >= 0.01 : \n",
    "        tag = \"pos\"\n",
    "    elif sentiment_dict['compound'] <= - 0.01 : \n",
    "        tag = \"neg\"\n",
    "    else : \n",
    "        tag = \"neut\" \n",
    "    return [tag, sentiment_dict['compound']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qiJQ_hLtZh5A"
   },
   "source": [
    "Let's append the output to 2 new columns in our dataframe. `.apply()` allows us to apply a function along an axis of the DataFrame. Also note the use of `zip()` here, allowing us to map the 2 returned values of our function to the tuple of variables we assign them to. Finally, note the `*` to unpack these containers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70972,
     "status": "ok",
     "timestamp": 1596642496788,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "JGuQNv2iZh5B"
   },
   "outputs": [],
   "source": [
    "df[\"sent\"], df[\"sent_compound\"] = zip(*df.selftext_clean.apply(sentiment_analyzer_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HzQ4EE_Zh5E"
   },
   "source": [
    "Let's have a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 70475,
     "status": "ok",
     "timestamp": 1596642496790,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "7Djl4vZQZh5E",
    "outputId": "c2616c2c-691a-492c-c185-eecf83fca32c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1637,
     "status": "ok",
     "timestamp": 1596642498453,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "jiBbH9XDZh5H",
    "outputId": "85185b72-09a8-4524-a120-c3bebdf44bf7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.hist(column=\"sent_compound\",bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ImtMT8OtZh5K"
   },
   "source": [
    "Let's see if these scores make sense. We'll print out the comment with the highest score (note: we could also use `.idxmax()` to find the comment with the highest score). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "svUJ4frjZh5K",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_id = df.sent_compound.idxmin()\n",
    "df.selftext_clean[min_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOafBLGmZh5M"
   },
   "source": [
    "That does look like a comment with lots of negative language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JLFyNfiSZh5M"
   },
   "source": [
    "### Optional assignment: working with sentiment scores\n",
    "\n",
    "You could use these sentiment scores for all kinds of purposes. \n",
    "\n",
    "First, you could look at comments with a high or low sentiment, and see what kinds of topics or concerns are discussed. \n",
    "\n",
    "You could train a Naive Bayes classifier (using the code we used above) to see whether sentiments in the posts tell you anything about what `flair_text` class that post falls under. You could also run a **regression analysis** to see if a post's sentiment score (X) is a predictor for something like the user score it received (y). Please see the additional notebook, I will share, \"5-X Regression\", if you're interested in that.\n",
    "\n",
    "You could also combine it with your **topic modeling** output, if that output is interesting. You could create a column in your DataFrame that tells you the most-associated topic with each post/comment (using the notebook from week 3), then see if certain topics relate to certain sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZG6RgR-NZh5P"
   },
   "source": [
    "## Training a sentiment analyzer using Naive Bayes\n",
    "\n",
    "The problem with unsupervised approaches such as the one above is that they typically have poor performance compared to a supervised approach, where we create the labels ourselves.\n",
    "\n",
    "Let's implement a Naive Bayes Classifier, based on our own sentiment labels. These labels will be based on **whether a commenter evaluates a post positively or negatively**. This requires a training set of samples which have known features and known classes. We can manually label a subset of our comments as positive or negative to form our training set. We will also use a different feature extraction technique this time (rather than using tfidf counts).\n",
    "\n",
    "So we need to:\n",
    "\n",
    "1. Create our own sentiment labels for part of our dataset, based on clear rules;\n",
    "2. Apply feature extraction techniques;\n",
    "3. Train a classifier for those labels, which we'll base on feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12286,
     "status": "ok",
     "timestamp": 1596643131163,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "e47vDb9iNA1O"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':\"1-LYy48UhoADWLlZKteH9zQT2myxQLiDC\"})   \n",
    "downloaded.GetContentFile('amita-comments_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15423,
     "status": "ok",
     "timestamp": 1596643134573,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "8rMN8u6PNA1S"
   },
   "outputs": [],
   "source": [
    "# load into df\n",
    "df_com = pd.read_csv(\"data/amita-comments.csv\", lineterminator='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15208,
     "status": "ok",
     "timestamp": 1596643134575,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "yn3XOMNrZOo1",
    "outputId": "972da1b8-2b45-44f6-9c9a-17a66280d76c"
   },
   "outputs": [],
   "source": [
    "# Get rid of empty values and reset index\n",
    "df_com = df_com[~df_com['body'].isin(['[removed]', '[deleted]' ])].dropna(subset=['body']).reset_index(drop=True)\n",
    "len(df_com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Jg6mF66Zh5P"
   },
   "source": [
    "Let's start labeling ourselves. If you want to be able to classify with some accuracy, you should do **at least a few thousand (!) posts or comments**. This'll take a couple of hours. But you'll have a labeled dataset you can use for all kinds of things!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1596643142998,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "mYIHY7-JZh5P"
   },
   "outputs": [],
   "source": [
    "df_com_labeled = df_com.iloc[1:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1596643144926,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "YTdmL4VTZh5R",
    "outputId": "8ec61cbb-0c9f-4fc3-d1f8-3d754737856a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_com_labeled[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "agTZddYKLI4g"
   },
   "source": [
    "Now, we'll loop over the rows and display the post for each row, and ask the user to label it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 871
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75466,
     "status": "error",
     "timestamp": 1596649114535,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "BDuuduo1Zh5T",
    "outputId": "dd2d4b0b-1442-42e1-86e0-22915ddce6ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classifications:\n",
    "# p: overall positive evaluation of OP\n",
    "# n: overall negative evaluation of OP\n",
    "# x: cannot determine evaluation of OP, or comment is made by OP\n",
    "\n",
    "for index, row in df_com_labeled.iterrows():\n",
    "    print(row.body)\n",
    "    df_com_labeled.loc[index, 'sentiment'] = input()\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1163,
     "status": "ok",
     "timestamp": 1596649181876,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "bO-iu-OBWAfZ",
    "outputId": "182e513c-90da-441b-ee1c-a69500db802f"
   },
   "outputs": [],
   "source": [
    "df_com_labeled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "91Im7zboZh5U"
   },
   "outputs": [],
   "source": [
    "# save your labels to csv\n",
    "df_com_labeled.to_csv('df_com_Sentiment_Labeled.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeQMd8r_Zh5W"
   },
   "source": [
    "(I've cheated here and randomly assigned some tags to the corpus in the cell below, just so you can see how this works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 690,
     "status": "ok",
     "timestamp": 1596643297563,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "z7gqnjajZh5X"
   },
   "outputs": [],
   "source": [
    "tags = ['p', 'n', 'x']\n",
    "df_com_labeled[\"sentiment\"] = np.random.choice(tags, 999, p=[0.3, 0.6, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1596643303122,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "QOPh8KLGZh5a"
   },
   "outputs": [],
   "source": [
    "df_com_labeled = df_com_labeled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "360smjSoZh5c"
   },
   "source": [
    "### Train, test, and cross-validation sets\n",
    "\n",
    "When building our sentiment analyzer, we need to create a test set again, in order to prevent overestimating its performance and overconstraining it. We will use the test set to evaluate the performance of our sentiment analyzer once it is complete.\n",
    "\n",
    "When designing our sentiment analyzer, we’ll have a number of choices to make along the way (which were made for us when using VADER). How many features should we use? Should we include the capitalization of words as a feature?  All of these **hyperparameters** will effect the performance of our sentiment analyzer. To maximize performance, it's best to evaluate our classifier under different hyperparameter settings. We could do this with the training set itself – but then we run into the same risk of overconstraining the analyzer that we discussed earlier. Using the test set would mean we'd be tuning our classifier to the test set – defeating the purpose of setting that data aside in the first place.\n",
    "\n",
    "So we'll set another portion of the original training set aside: the **cross-validation** set. We can use it to evaluate the performance of our sentiment analyzer as we tune our hyperparameters. This means the final evaluation of our analyzer’s performance will be a true representation of how it will perform on unlabeled comments from our full collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VaoUY9EeZh5c"
   },
   "source": [
    "First, let's have a look at how much we've done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1596643308391,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "EtM8c38cZh5c",
    "outputId": "c8e30167-2f5b-4bd7-b7a5-1274c78b210f"
   },
   "outputs": [],
   "source": [
    "pos_comments = [(df_com_labeled.loc[row,'body'],'positive') for row in range(len(df_com_labeled)) if \n",
    "              df_com_labeled.loc[row,'sentiment'] == 'p']\n",
    "\n",
    "neg_comments = [(df_com_labeled.loc[row,'body'],'negative') for row in range(len(df_com_labeled)) if \n",
    "              df_com_labeled.loc[row,'sentiment'] == 'n']\n",
    "\n",
    "print('Number of comments labeled positive: %d' % len(pos_comments))\n",
    "print('Number of comments labeled negative: %d' % len(neg_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZrz94ppZh5h"
   },
   "source": [
    "Note that you see a class imbalance here – we have way more negative than positive labels. This presents a new challenge for our sentiment analyzer. If the probability of seeing positive comments is small, Bayes Theorem is likely to predict that the probability of any comment being positive is small **regardless of the evidence**. So we need to up- or downsample again.\n",
    "\n",
    "The choice of upsampling, downsampling, or randomly sampling (producing the true positive to negative ratio) is a **hyperparameter** of our sentiment analyzer. To know which method will work best, we ought to try all of them and see which yields the best performance on your cross-validation set. \n",
    "\n",
    "For now, we will put half of the positive and negative comments into the **training set** while down sampling negative tweets at a one-to-one ratio. Half of the remaining comments will go into the **cross-validation set**, and the final quarter of comments into the **test set**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1096,
     "status": "ok",
     "timestamp": 1596643340836,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "HNmykxYsZh5i"
   },
   "outputs": [],
   "source": [
    "# Half of the positive comments go in training\n",
    "# Downsampling the negative comments at 1 pos:1 neg\n",
    "\n",
    "len_train = int(round(len(pos_comments)/2)*2) # Define total len of train set based on len of pos_comments\n",
    "train_comments = pos_comments[:int(len_train/2)] + neg_comments[:int(len_train/2)]\n",
    "\n",
    "# Half of the remaining half go in cv\n",
    "cv_neg_cutoff = int((len_train/2) + round((len(neg_comments) - len_train/2)/2))\n",
    "cv_pos_cutoff = int((len_train/2) + round((len(pos_comments) - len_train/2)/2))\n",
    "cv_comments = neg_comments[int(len_train/2):cv_neg_cutoff] + pos_comments[int(len_train/2):cv_pos_cutoff]  \n",
    "\n",
    "# Rest go into testing\n",
    "test_comments = neg_comments[cv_neg_cutoff:] + pos_comments[cv_pos_cutoff:]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 623,
     "status": "ok",
     "timestamp": 1596643342256,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "nOEq3z-rZh5k",
    "outputId": "71a316db-52ec-4189-de49-28e3634ddd8e"
   },
   "outputs": [],
   "source": [
    "## Test\n",
    "train_comments[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m61KpDj8Zh5p"
   },
   "source": [
    "(Note that you can do this kind of splitting through scikit-learn's `train_test_split()` and `KFold()` methods, making it much easier!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e8rANawSZh5q"
   },
   "source": [
    "## Feature extraction design\n",
    "\n",
    "Now it's time to define our sentiment analyzer’s features. We'll do so with boolean `contains(word)` statements. For instance, the feature `contains(disagree)` will likely be `True` for a negative comment, and `False` for a positive tweet. We’ll need to construct a list of useful words for this purpose.\n",
    "\n",
    "### Bigrams\n",
    "Note that this is harder than it might seem! If we were to train a model that believes the word “like” indicates a positive tweet, we would misclassify the second tweet. It’s clear that the classifier’s performance would increase if it could recognize that the word “not” is negating the word “like.” One way to address negation markers is to include **bigrams** in our list of features. Doing so allows our classifier to recognize the collocation of words such as “(not,like)” in addition to the typical unigram features we would extract.\n",
    "\n",
    "### Preventing overfit\n",
    "This word list shouldn’t include every word we come across in our collection of comments: using too many uncommon words will cause our sentiment analyzer to *overfit* the training sample. This usually happens when the model is too complex (that is, using too many features compared to the number of observations). Such a model will be very accurate on the training data  not accurate on untrained or new data. \n",
    "\n",
    "We will avoid this issue by requiring that each word **appear a certain number of times** before we consider it as a feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-2R_UEWcZh5q"
   },
   "source": [
    "Let's write a function that applies these feature extraction techniques to our comments. First, we extract a list of unigrams and bigrams. We treat all html URLs as the same “word”, while excluding punctuation and capitalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3069,
     "status": "ok",
     "timestamp": 1596643443668,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "lDnFIjDEZh5q"
   },
   "outputs": [],
   "source": [
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "import string\n",
    "import itertools\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "punct = set(string.punctuation)\n",
    "\n",
    "def filter_comments(comments):\n",
    "    filtered_bigrams = []\n",
    "    for words, sentiment in comments: \n",
    "        words_filtered = []\n",
    "        # Lemmatize using spacy\n",
    "        words = words.lower()\n",
    "        doc = simple_preprocess(str(words), deacc=True)     \n",
    "        words_filtered.extend([token for token in doc])\n",
    "        # Identify top 200 bigams using chi_sq measure of importance\n",
    "        bigram_finder = BigramCollocationFinder.from_words(words_filtered)\n",
    "        bigrams = bigram_finder.nbest(BigramAssocMeasures.chi_sq, 200)      \n",
    "        # Add to filtered list\n",
    "        filtered_bigrams.append(([ngram for ngram in itertools.chain(words_filtered,bigrams)],sentiment))\n",
    "    return filtered_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x_UGUXOiZh5s"
   },
   "source": [
    "The result of the filter is a **list of tuples** for each comment. The first entry in each tuple is a list of unigrams and bigrams for that comment, and the second entry in the tuple is the manually labeled sentiment of that comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2493,
     "status": "ok",
     "timestamp": 1596643443670,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "N3BFjJxcZh5s"
   },
   "outputs": [],
   "source": [
    "train_tuples = filter_comments(train_comments)\n",
    "cv_tuples = filter_comments(cv_comments)\n",
    "test_tuples = filter_comments(test_comments)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2134,
     "status": "ok",
     "timestamp": 1596643443671,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "dAsAEp19Zh5u",
    "outputId": "a8d9dc2b-b873-413b-d625-ac827693abb8"
   },
   "outputs": [],
   "source": [
    "train_tuples[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P1L87VWyZh5w"
   },
   "source": [
    "Remember that we wanted to get rid of the features that do not appear frequently? We'll now remove all unigrams or bigrams that appear less than 3 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2974,
     "status": "ok",
     "timestamp": 1596643449898,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "Nkzc_gQRZh5w"
   },
   "outputs": [],
   "source": [
    "def get_word_features(comments,min_freq):\n",
    "    word_list = []\n",
    "    for word_or_tuple in comments:\n",
    "        word_list.extend(word_or_tuple[0])\n",
    "    # Count the frequency of each unigram and bigram\n",
    "    freqs = FreqDist(word_list)\n",
    "    # Sort based on frequency\n",
    "    sorted_word_list = sorted(freqs.items(), key=lambda x: x[1], reverse=True)\n",
    "    # Only include features appearing at least min_freq times\n",
    "    word_features = [sorted_word_list[word][0] for word in \n",
    "                     range(len(sorted_word_list)) if sorted_word_list[word][1] >= min_freq]    \n",
    "    # Return list of features\n",
    "    return word_features\n",
    "\n",
    "word_features = get_word_features(train_tuples, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zg-NrYicZh5y"
   },
   "source": [
    "Let's see how many features we have found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2214,
     "status": "ok",
     "timestamp": 1596643449900,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "x2XaBC_FZh50",
    "outputId": "b32c7aa5-dcbe-4f40-c8ad-cf34b4829cb9"
   },
   "outputs": [],
   "source": [
    "len(word_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fgtUvhEpZh53"
   },
   "source": [
    "Now that we have a final list of word features, we can finally evaluate the boolean `contains(word_feature)` statements for each tweet. To do so, we first define an `extract_features()` function that takes a filtered comment as an input, then determines if each word feature exists in the filtered comment’s list of unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 973,
     "status": "ok",
     "timestamp": 1596643453698,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "zJcBp3buZh53"
   },
   "outputs": [],
   "source": [
    "def extract_features(filtered_comment):\n",
    "    filtered_comment_words = set(filtered_comment)\n",
    "    features = {}\n",
    "    for word in word_features:        \n",
    "        # Check if word feature is present in filtered_comment\n",
    "        features['contains(%s)' % str(word)] = (word in filtered_comment_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZI1Ko2tZh55"
   },
   "source": [
    "The NLTK classify package provides a convenient `.apply_features()` method to apply our `extract_features()` function to each comment in our datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1596643454841,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "Slh4a-LVZh55"
   },
   "outputs": [],
   "source": [
    "training_set = apply_features(extract_features, train_tuples)\n",
    "cv_set = apply_features(extract_features, cv_tuples)\n",
    "test_set = apply_features(extract_features, test_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBe5Nx_uZh58"
   },
   "source": [
    "The final result is a NLTK `LazyMap` object that contains a tuple for each comment. The first entry in the tuple is a list of boolean `contains(word)` features for each of the feature words we selected, while the second entry in the tuple is the manually labeled sentiment of the comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwfHfQm4Zh58"
   },
   "outputs": [],
   "source": [
    "training_set[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Y1gopnJZh59"
   },
   "source": [
    "## Training the classifier\n",
    "\n",
    "It's Time to train our Naive Bayes Classifier. Let's use NLTK's one this time around.\n",
    "\n",
    "Note that we're using Bayesian classfier over **binary features** this time: that is, we use a bunch of boolean `contains()` variables that tell our classifier whether or not some feature is present in a comment. The equivalent in sklearn for this is the `BernoulliNB` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1682,
     "status": "ok",
     "timestamp": 1596643470530,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "azOLyVO9Zh5-"
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eOIk4_iGZh5_"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "To accurately evaluate the performance of our classifier, we have to look at 2 things: **precision** and **recall**.\n",
    "\n",
    "- **Precision:** the number of true positives (correctly labeled items) divided by the sum of true positives and false positives (incorrectly labeled items)\n",
    "- **Recall:** the number of true positives divided by the total number of elements that actually belong to the positive class (i.e., the sum of true positives and false negatives).\n",
    "\n",
    "We can average the precision and recall metrics using their harmonic mean, producing a quantity known as the F1 score. It's a measure of a test's total accuracy. See https://en.wikipedia.org/wiki/F1_score for more.\n",
    "\n",
    "We'll use a function that evaluates our classifier, based on the cross-validation set we created earlier. We'll calculate F1, precision and recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 898,
     "status": "ok",
     "timestamp": 1596643474092,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "LYlJ092JZh6A"
   },
   "outputs": [],
   "source": [
    "def eval_classifier(data_set):\n",
    "    # NLTK .accuracy method calculates accuracy\n",
    "    cross_valid_accuracy = accuracy(classifier, data_set)\n",
    "\n",
    "    # Create two sets to count positive and negative comments\n",
    "    ref_set = collections.defaultdict(set)\n",
    "    obs_set = collections.defaultdict(set)\n",
    "\n",
    "    # Loop over each comment in our cross validation set\n",
    "    for i, (feats, label) in enumerate(data_set):\n",
    "\n",
    "        #Classify the comment by feeding the classifier the comment's features\n",
    "        observed = classifier.classify(feats)\n",
    "\n",
    "        #Add the current comment to the \"reference\" set under the actual class\n",
    "        ref_set[label].add(i)\n",
    "\n",
    "        #Add the current coment to the \"observation\" set under the predicted class\n",
    "        obs_set[observed].add(i)\n",
    "\n",
    "    # Calculate F score, precision, an recall for positive and negative labels\n",
    "    print ('Accuracy:', cross_valid_accuracy)\n",
    "    print ('F-measure [negative]:', fmeas(ref_set['negative'], obs_set['negative']))\n",
    "    print ('F-measure [positive]:', fmeas(ref_set['positive'], obs_set['positive']))\n",
    "    print ('Precision [negative]:', prec(ref_set['negative'], obs_set['negative']))\n",
    "    print ('Precision [positive]:', prec(ref_set['positive'], obs_set['positive']))\n",
    "    rec_neg=rec(ref_set['negative'], obs_set['negative'])\n",
    "    rec_pos=rec(ref_set['positive'], obs_set['positive'])\n",
    "    print ('Recall [negative]:', rec_neg)\n",
    "    print ('Recall [positive]:', rec_pos)\n",
    "    total_neg=len(neg_comments)\n",
    "    total_pos=len(pos_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4184,
     "status": "ok",
     "timestamp": 1596643479909,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "2jyUjj1rZh6B",
    "outputId": "4a7441e9-29da-49f5-a687-018df8464a72",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_classifier(cv_set) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWX9jXceZh6E"
   },
   "source": [
    "At this point, we have to see if we are happy with the outcome of our performance metrics. \n",
    "If not, we need to change the hyperparameters of our classifier and revaluate its performance on our cross-validation set. As noted, we may want to consider limiting our classifier to **high-information features**. We can check what these features are using NLTK’s `show_most_informative_features()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1086,
     "status": "ok",
     "timestamp": 1596643487241,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "s5UN9b4lZh6E",
    "outputId": "3c905c6a-f56a-4bfb-8cef-42aa53e0f9e4",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classifier.show_most_informative_features(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aZ0u-rfmZh6F"
   },
   "source": [
    "We can use these features in the *feature extraction design* step above to see if it will improve our model (which it won't necessarily will). **The goal is, through tweaking our hyperparameters like this, to improve the accuracy of our model.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jddy_7cMZh6F"
   },
   "source": [
    "### Evaluating on the test set\n",
    "\n",
    "It's only after tweaking our model for a while that we should crack open our test set and see how well our classifier has done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4157,
     "status": "ok",
     "timestamp": 1596643503701,
     "user": {
      "displayName": "Tom van Nuenen",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhtEyfMMXnweSdKHvOqheyZd6KLkXGOtz3AYYAIBA=s64",
      "userId": "10012302451096885058"
     },
     "user_tz": -180
    },
    "id": "EOQtSampZh6G",
    "outputId": "1d5f37d5-5e00-468f-f5b7-503e9ca51fe8"
   },
   "outputs": [],
   "source": [
    "eval_classifier(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TafGz4uTZh6I"
   },
   "source": [
    "## Conclusion: Data analysis and hermeneutics\n",
    "\n",
    "That was a lot! Again, don't worry if you didn't understand every part of this notebook. Its main purpose is for you to get a first look into the many ways in which data scientists can classify their data.\n",
    "\n",
    "There's a lot you can do with the methods we've applied here. For instance, you can use classification to try and find binaries in your dataset. You could tag a corpus manually, based on the presence of some binary category X or Y that you deem important. You could also create a set of categories based on, say, particular word frequencies. Then you can create a classifier to see if you can successfully predict these categories in other texts.\n",
    "\n",
    "You can use classification, feature extraction and sentiment analysis to explore your own data. For instance:\n",
    "- Using sentiment scores to trace posts or topics of interest;\n",
    "- Using feature extraction to create new classes; \n",
    "- Training a classifier based on your own classes (e.g. the presence of a specific topic you're interested in)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KAZIndhPZh2k",
    "0jMbvaKPZh3s",
    "_tAYGMaxZh37",
    "86yH3K8gZh37",
    "wH_tIIPyZh4m",
    "bOST9QEgZh42",
    "JLFyNfiSZh5M",
    "360smjSoZh5c",
    "eOIk4_iGZh5_",
    "Jddy_7cMZh6F"
   ],
   "name": "Week 5-3 Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
